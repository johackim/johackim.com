{"pageProps":{"source":"<link rel=\"preload\" as=\"image\" href=\"https://i.imgur.com/e6l8DD5.png\"/><link rel=\"preload\" as=\"image\" href=\"https://i.imgur.com/lO3QlRr.png\"/><div class=\"space-y-4 whitespace-normal *:first:mt-0 *:last:mb-0\"><p>Je me suis récemment donné comme projet de devenir hébergeur indépendant chez les <strong>CHATONS</strong> (le <strong>C</strong>ollectif des <strong>H</strong>ébergeurs <strong>A</strong>lternatifs, <strong>T</strong>ransparents, <strong>O</strong>uverts, <strong>N</strong>eutres et <strong>S</strong>olidaires). Étant seul à maintenir les services de mes clients, j’ai dû concevoir une infrastructure <strong>sécurisée</strong>, <strong>performante</strong>, <strong>scalable</strong>, <strong>automatisée</strong> et <strong>facile à maintenir</strong>. Je vais à travers cet article vous décrire les étapes à suivre pour monter ce type d’infrastructure.</p><h2>1. Présentation de l&#x27;infrastructure</h2><p>Dans cette infrastructure, chaque application tourne sous forme d’un ou plusieurs conteneurs répartis sur un ou plusieurs serveurs selon leurs ressources disponibles.</p><p><img src=\"https://i.imgur.com/e6l8DD5.png\" alt=\"Infrastructure\"/></p><p>Les <strong>conteneurs</strong> permettent d’<strong>accélérer et faciliter le déploiement des applications</strong>, ils contiennent toutes les dépendances d’une application et sont indépendants vis-à-vis de l’infrastructure hôte. Additionné à un orchestrateur, par exemple <strong>Docker Swarm</strong>, on dispose d’un système qui exécute, coordonne et <strong>gère entièrement le cycle de vie de nos applications</strong>.</p><p>Aujourd’hui je démarre mon infrastructure avec trois petits serveurs, demain elle pourra <strong>évoluer facilement</strong> suivant l’augmentation des demandes clients.</p><p>Plutôt que de gérer mon infrastructure sous forme de <strong>tâches manuelles et répétitives</strong>, une grande partie est gérée à l’aide de <strong>fichiers de définition</strong> que je versionne. Dans mon cas, il s’agit principalement de fichiers <strong>YAML</strong>.</p><p>Si jamais tous mes serveurs venaient à être stoppés ou supprimés inintentionnellement, je peux à priori tout restaurer en moins d’une heure du moment que je dispose des <strong>backups</strong>.</p><p>Une fois l’infrastructure mise en place, il est possible de démarrer une application en seulement une ligne de commande, par exemple :</p><ul>\n<li>Un <strong>tchat</strong> (ex : rocket.chat)</li>\n<li>Un <strong>blog</strong> (ex : WordPress, Joomla, Ghost)</li>\n<li>Un <strong>site e-commerce</strong> (ex : PrestaShop)</li>\n<li>Un <strong>espace de stockage</strong> (ex : ownCloud, Nextcloud)</li>\n<li>Un <strong>système de facturation</strong> (ex : Invoice Ninja)</li>\n<li>Un <strong>système de monitoring et d’alerting</strong> (ex : Grafana + Prometheus + Alertmanager)</li>\n</ul><p>Le tout avec un <strong>nom de domaine</strong> et un <strong>certicat SSL</strong> associé automatiquement.</p><h2>2. Déploiement des serveurs</h2><p>Aujourd’hui je dispose de <strong>trois serveurs Ubuntu Xenial chez Scaleway</strong>. <strong>Un serveur <a class=\"\" target=\"_blank\" href=\"https://scaleway.com/pricing/#anchor_baremetal\">C2S</a></strong> en tant que master et <strong>deux serveurs <a class=\"\" target=\"_blank\" href=\"https://scaleway.com/pricing/#anchor_starter\">START1-S</a></strong> en tant que workers. Si vous le souhaitez, vous pouvez commencer avec un seul serveur dans un premier temps. De même, il est tout à fait envisageable de créer ce type d’infrastructure sur votre propre matériel physique si vous en avez les moyens.</p><p>Première étape on installe <strong>docker</strong> sur chaque serveur :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">apt-get update; apt-get upgrade; apt-get dist-upgrade;\napt-get install -y apt-transport-https\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\nsudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;\nsudo apt-get update; sudo apt-get install -y docker-ce\n</code></pre></div><p>Ensuite, on initialise Docker Swarm sur le serveur master :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker swarm init --advertise-addr eth0:2377\n</code></pre></div><p>Puis, on joint les serveurs workers au serveur master :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker swarm join --token &lt;token&gt; &lt;mondomaine.priv.cloud.scaleway.com&gt;:2377\n</code></pre></div><p><strong>Note</strong>: Scaleway change les adresses IP privées lors du redémarrage des serveurs. Pour cette raison je dois faire communiquer les serveurs entre eux par leurs domaines privés qui eux restent fixes. Si vous ne passez pas par Scaleway vous pouvez utiliser des adresses IP directement.</p><p>Pour la configuration du <strong>swap</strong>, voilà les commandes que j&#x27;exécute :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">fallocate -l 2G /swap\nmkswap /swap\necho &quot;/swap  none  swap  sw 0  0&quot; &gt;&gt; /etc/fstab\nswapon -a\necho &quot;vm.swappiness = 10&quot; &gt;&gt; /etc/sysctl.d/99-swap.conf\nsed -i -e &#x27;s/GRUB_CMDLINE_LINUX=&quot;&quot;/GRUB_CMDLINE_LINUX=&quot;cgroup_enable=memory swapaccount=1&quot;/g&#x27; /etc/default/grub\nupdate-grub\n</code></pre></div><h2>3. Persistence des données</h2><p>Une application <strong>stateful</strong>, contrairement à une application stateless, a besoin de persister certaines données comme une base de données (des fichiers de configurations ou de simples fichiers images par exemple). On utilise pour ça les <strong>volumes docker</strong>. De plus, avec <strong>Docker Swarm</strong>, les containers sont volatiles et ne restent pas toujours reliés à un unique serveur. Il faut donc utiliser un <a class=\"\" target=\"_blank\" href=\"https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins\">volume driver</a>.</p><h3>Un espace de stockage flexible</h3><p>Afin d’éviter d’éparpiller les données et étendre facilement la taille de notre espace de stockage, j’ai créé une <strong>partition LVM</strong> (Logical Volume Manager) qui combine plusieurs volumes de données. Au fur et à mesure que l’infrastructure grandit, il est possible d’ajouter nos volumes de données à cette partition.</p><p>Avec Scaleway, il est très simple d’ajouter et de relier des volumes de données à un serveur. Une fois nos volumes reliés, nous pouvons les combiner ensemble pour former <strong>un seul point de montage</strong>.</p><p>L’installation se fait sur notre serveur master :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">apt-get install -y lvm2\nsystemctl start lvm2-lvmetad.socket\npvcreate /dev/{nbd1,nbd2}\nvgcreate lvm /dev/nbd1 /dev/nbd2\nlvcreate -l 100%FREE -n storage lvm\nmkfs -t ext4 /dev/lvm/storage\necho &quot;/dev/mapper/lvm-storage /mnt ext4 rw,relatime 0 0&quot; &gt;&gt; /etc/fstab\nmount -a\nsed -i -e &#x27;s/use_lvmetad = 1/use_lvmetad = 0/g&#x27; /etc/lvm/lvm.conf\n</code></pre></div><p>À l’avenir, si vous souhaitez <strong>agrandir votre espace de stockage</strong> via d’autres volumes, il suffit simplement d’exécuter les commandes suivantes :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">umount /mnt\nvgextend lvm /dev/nbd3\nlvextend -l +100%Free /dev/lvm/storage\nresize2fs /dev/lvm/storage\nmount -a\n</code></pre></div><h3>Volume driver</h3><p>Le <a class=\"\" target=\"_blank\" href=\"https://docs.docker.com/engine/extend/legacy_plugins/#volume-plugins\">volume driver</a> que j’ai choisi s’appelle docker-volume-netshare. Chaque application persistera ses données sur un serveur NFS.</p><p>On installe notre <strong>serveur NFS</strong> sur notre master :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">sudo apt-get install -y nfs-kernel-server\nsudo mkdir /mnt/data\n</code></pre></div><p>Puis on autorise tous les serveurs à s’y connecter :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\"># /etc/exports\n/mnt/data 127.0.0.1(rw,sync,no_subtree_check,no_root_squash) worker-01.priv.cloud.scaleway.com(rw,sync,no_subtree_check,no_root_squash) worker-02(rw,sync,no_subtree_check,no_root_squash)    \n</code></pre></div><p>On redémarre notre serveur afin d’appliquer notre configuration :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">sudo systemctl restart nfs-kernel-server\n</code></pre></div><p>Puis on installe sur tous les serveurs le package nfs-common et notre <strong>volume</strong> driver docker-volume-netshare :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">sudo apt-get install -y nfs-common\n</code></pre></div><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">sudo wget -O /usr/bin/docker-volume-netshare https://github.com/ContainX/docker-volume-netshare/releases/download/v0.35/docker-volume-netshare_0.35_linux_amd64-bin\nsudo chmod +x /usr/bin/docker-volume-netshare\n</code></pre></div><p>On crée <strong>un service</strong> docker-volume-netshare qui sera lancé à chaque démarrage serveur :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-service\"># /etc/systemd/system/docker-volume-netshare.service\n[Unit]\nDescription=Docker NFS, AWS EFS &amp; Samba/CIFS Volume Plugin\nDocumentation=https://github.com/gondor/docker-volume-netshare\nWants=network-online.target\nAfter=network-online.target\nBefore=docker.service\n\n[Service]\nExecStart=/usr/bin/docker-volume-netshare nfs\nStandardOutput=syslog\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></div><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">systemctl enable docker-volume-netshare.service\nsystemctl start docker-volume-netshare.service\n</code></pre></div><p>Pour vérifier si tout fonctionne correctement, vous pouvez créer un volume « test » :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker volume create --driver nfs --name=test --opt share=127.0.0.1:/mnt/data --opt create=true\n</code></pre></div><p>Puis créer un fichier « test » depuis un container :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker run --rm -v test:/mount alpine touch /mount/test\n</code></pre></div><p>Ce fichier devrait apparaître dans le répertoire /mnt/data de votre serveur master.</p><h2>4. Sauvegardes automatisées</h2><p><strong>Objectif</strong> : Créer un système de sauvegarde journalier de tous les <strong>volumes</strong>.</p><p>Pour sauvegarder nos volumes il nous suffit de sauvegarder notre dossier /mnt/data avec notre outil de backup préféré (borg, restic, duplicity, etc.).</p><p>Personnellement j’utilise <strong>restic</strong> :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">wget https://github.com/restic/restic/releases/download/v0.9.3/restic_0.9.3_linux_amd64.bz2\nbzip2 -d restic_0.9.3_linux_amd64.bz2\nmv restic_0.9.3_linux_amd64 /usr/local/bin/restic\nchmod +x /usr/local/bin/restic\n</code></pre></div><p>Le processus de sauvegarde est très simple avec restic :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">restic -r &lt;repository&gt; init\nrestic -r &lt;repository&gt; backup /mnt/data\n</code></pre></div><p>Il existe plusieurs types de <strong>repository</strong> : local, S3, sftp, rclone, etc. Personnellement j’utilise <strong>S3</strong>, car Scaleway propose un <strong>Object Storage</strong> comme AWS, du coup j’en profite.</p><p>On automatise ensuite la sauvegarde avec une <strong>tâche cron</strong> :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\"># crontab -e\n0 0 * * * /usr/local/bin/restic -r &lt;repository&gt; backup /mnt/data\n</code></pre></div><h3>Restauration</h3><p>Dans le cas où vous souhaitez récupérer une sauvegarde précédente :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">restic -r &lt;repository&gt; snapshots\nrestic -r &lt;repository&gt; restore &lt;snapshotID&gt; -t restore\n</code></pre></div><h2>5. Reverse-proxy et Let’s Encrypt</h2><p><strong>Objectif</strong>: Configurer un <strong>reverse proxy</strong> pour accéder à nos applications via un <strong>unique point d’entrée</strong>.</p><p>Personnellement, j’utilise <strong>Traefik</strong>, qui est compatible avec <strong>Docker Swarm</strong>.</p><p>On crée <strong>un network</strong> que l’on nomme par exemple <strong>traefik-net,</strong> il sera utilisé pour relier de manière automatique chaque application à <strong>Traefik</strong> à l’aide des <strong>labels</strong>.</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker network create --driver=overlay traefik-net\n</code></pre></div><p>Puis on déploie <strong>Traefik</strong> uniquement sur notre serveur master :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-yml\"># traefik.yml\n\nversion: &quot;3.3&quot;\nservices:\n  traefik:\n    image: traefik\n    command: --docker \\\n      --docker.swarmMode \\\n      --docker.watch\n    ports:\n      - &quot;80:80&quot;\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    deploy:\n      placement:\n        constraints: [node.role==manager]\n\nnetworks:\n  default:\n    external:\n      name: traefik-net\n</code></pre></div><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker stack deploy -c traefik.yml traefik\n</code></pre></div><p>Enfin, pour relier une application à notre <strong>reverse proxy</strong>, on peut créer un <strong>service</strong> docker avec des <strong>labels</strong> qui indiqueront à <strong>Traefik</strong> de diriger le traffic HTTP du domaine <a class=\"\" target=\"_blank\" href=\"https://johackim.com\">johackim.com</a> sur le(s) bon(s) container(s) :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker service create --name blog --network traefik-net -l traefik.port=2368 -l traefik.frontend.rule=Host:johackim.com -l traefik.enable=true ghost\n</code></pre></div><h3>Let’s Encrypt</h3><p>Pour <strong>automatiser la création de certificats SSL</strong> des services exposés à l’extérieur de mon cluster, j’ai configuré <strong>Traefik</strong> avec ce fichier de configuration :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-toml\"># traefik.toml\n\ndebug = true\nlogLevel = &quot;DEBUG&quot;\ndefaultEntryPoints = [&quot;https&quot;,&quot;http&quot;]\n\n[entryPoints]\n  [entryPoints.http]\n  address = &quot;:80&quot;\n    [entryPoints.http.redirect]\n    entryPoint = &quot;https&quot;\n  [entryPoints.https]\n  address = &quot;:443&quot;\n    [entryPoints.https.tls]\n\n[acme]\nemail = &quot;contact@example.com&quot;\nstorage = &quot;acme.json&quot;\nacmeLogging = true\nentryPoint = &quot;https&quot;\nonHostRule = true\n\n[acme.httpChallenge]\n  entryPoint = &quot;http&quot;\n</code></pre></div><h2>6. Infrastructure as Code</h2><p>Toutes les applications sont définies sous forme de code. <strong>Un fichier YAML</strong> représente tout ce que contient une application (<strong>services, volumes, networks</strong>).</p><p>Voici comme exemple le fichier ghost.yml que j’utilise pour le déploiement de mon blog :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-yml\"># ghost.yml\n\nversion: &#x27;3&#x27;\n\nservices:\n  web:\n    image: ghost:2.4.0\n    volumes:\n      - ghost:/var/lib/ghost/content:nocopy\n    environment:\n      url: ${SCHEME:-http}://${DOMAIN:?err}\n    deploy:\n      labels:\n        traefik.port: 2368\n        traefik.frontend.rule: Host:${DOMAIN:?err}\n        traefik.enable: &quot;true&quot;\n\nvolumes:\n  ghost:\n    driver: nfs\n    driver_opts:\n      share: master.priv.cloud.scaleway.com:/mnt/data\n      create: &quot;true&quot;\n\nnetworks:\n  default:\n    external:\n      name: traefik-net\n</code></pre></div><p>En une seule commande, je peux déployer un blog ghost sous le nom de domaine que je souhaite, et avec un certificat ssl automatiquement attribué :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">SCHEME=https DOMAIN=johackim.com docker stack deploy -c ghost.yml blog\n</code></pre></div><p>J’ai créé d’autres stacks que <strong>Ghost</strong>, je vous invite à vous rendre sur <a class=\"\" target=\"_blank\" href=\"https://github.com/ethibox/awesome-stacks/\">ce repository</a> si vous désirez en voir d’autres.</p><h2>7. Monitoring, alerting et logging</h2><p>Pour <strong>monitorer</strong> tous mes serveurs, pour être <strong>alerté</strong> à chaque fois qu’une application ne renvoie pas un <strong>code 200</strong> ou qu’un <strong>CPU, RAM, Disque</strong> dépasse les 95% d’utilisation. Je me suis créé une <a class=\"\" target=\"_blank\" href=\"https://raw.githubusercontent.com/ethibox/awesome-stacks/ee0f0474bb8237b32f1a0a84a12275ed855362d4/monitoring.yml\">stack avec grafana, prometheus et alertmanager</a>.</p><p><img src=\"https://i.imgur.com/lO3QlRr.png\" alt=\"Dashboard Grafana\"/></p><p>Et d’une commande, je peux tout installer :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">DOMAIN_GRAFANA=grafana.mondomaine.fr DOMAIN_PROMETHEUS=prometheus.mondomaine.fr docker stack deploy -c monitoring.yml monitoring\n</code></pre></div><p><a class=\"\" target=\"_blank\" href=\"https://github.com/ethibox/awesome-stacks/blob/91c336d4c42b3b2dd056a15b65c1d996ce08c236/elastic.yml\">La stack elastic</a> quant à elle, va me servir à <strong>logger tout le traffic HTTP entrant</strong> sur <strong>Traefik</strong> et <strong>collecter les syslog</strong> de chaque serveur.</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">DOMAIN=kibana.mondomaine.fr docker stack deploy -c elastic.yml elastic\n</code></pre></div><h2>8. Sécurité</h2><p>En termes de sécurité, je provisionne tous mes serveurs avec un <a class=\"\" target=\"_blank\" href=\"https://github.com/johackim/ansible-personal\">playbook</a> Ansible. Concrètement, je configure tous mes serveurs avec un <strong>IPS</strong> (fail2ban), un <strong>firewall</strong> (iptables) et des <strong>règles de system hardening</strong>.</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">ansible-playbook playbook.yml -u root -i &lt;PUBLIC_IP&gt;,\n</code></pre></div><p>Je crée aussi des règles de sécurité avec les <strong>security group</strong> de Scaleway, puis des <strong>headers HTTP sécurisés</strong> pour chaque application :</p><div class=\"relative group\"><button type=\"button\" class=\"invisible group-hover:visible absolute top-0 right-0 rounded-md text-xs bg-gray-300 m-3 p-1.5 cursor-pointer leading-none\">Copier</button><pre><code class=\"language-bash\">docker service update &lt;name_app&gt; --label-add traefik.frontend.headers.customResponseHeaders=&quot;X-XSS-Protection: 1; mode=block&quot;\n</code></pre></div><h2>Conclusion</h2><p>De manière subjective, c’est la solution idéale pour moi, après avoir testé plusieurs solutions (<strong>Kubernetes, Helm, Ark, Ceph, Rook, Minio et Rexray</strong>) c’est celle qui dans mon cas est la plus <strong>accessible, maintenable, scalable</strong> et <strong>performante</strong>.</p><p>Sa scalabilité me permet d’<strong>éviter d’investir trop d’argent</strong> dans de très gros serveurs et d’<strong>évoluer proportionnellement</strong> à la demande des clients.</p><p>Je pense avoir créé une bonne base, il me reste sûrement encore beaucoup de choses à améliorer, dont par exemple :</p><ul>\n<li>Ajouter des <strong><a class=\"\" target=\"_blank\" href=\"https://docs.docker.com/compose/compose-file/#healthcheck\">healthcheck</a></strong> et <strong><a class=\"\" target=\"_blank\" href=\"https://docs.docker.com/config/containers/resource_constraints/\">limite de ressource</a></strong> Docker</li>\n<li>Me créer un <strong>Siem</strong> avec la stack <strong>Elastic</strong> et <strong>Surricata</strong></li>\n<li>Générer de manière aléatoire et automatique les mots de passes dans des <strong>docker secrets</strong>.</li>\n<li><strong>Auto-héberger</strong> toute l’infrastucture chez moi sur mon propre matériel, pour ne plus dépendre de <strong>Scaleway</strong>.</li>\n<li>Un <strong>stockage distribué</strong></li>\n</ul><p>N’hésitez pas à me dire dans les commentaires si vous avez des suggestions d’améliorations !</p><hr/><p>Références :</p><ul>\n<li>\n<a class=\"\" href=\"/hebergement-web\">Hébergement web</a>\n\n</li>\n</ul></div>","isIndex":false,"file":"Mon infrastructure en tant qu'hébergeur web indépendant.md","fileName":"Mon infrastructure en tant qu'hébergeur web indépendant","title":"Mon infrastructure en tant qu'hébergeur web indépendant","comments":true,"permalink":"infrastructure-hebergeur-web-independant","datePublished":"2019-01-01T18:40","dateUpdated":"2019-01-01T18:40","description":"En tant que membre des CHATONS (Collectif des Hébergeurs Alternatifs, Transparents, Ouverts, Neutres et Solidaires) et étant seul à maintenir les services de mes clients, je me suis conçu une infrastructure sécurisée, performante, scalable, automatisée et facile à maintenir.","publish":true,"rss":true},"__N_SSG":true}